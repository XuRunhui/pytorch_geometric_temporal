# Single GPU trainer configuration
# @package trainer

# Basic training settings
max_epochs: 200
min_epochs: 10
check_val_every_n_epoch: 1

# Hardware settings
accelerator: "gpu"
devices: 1
strategy: "auto"
precision: "16-mixed"

# Performance optimizations
benchmark: true
deterministic: false

# Training behavior
gradient_clip_val: 1.0
gradient_clip_algorithm: "norm"
accumulate_grad_batches: 1

# Logging and monitoring
log_every_n_steps: 1
enable_progress_bar: true
enable_model_summary: true

# Validation and testing
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0
val_check_interval: 1.0

# Checkpointing
enable_checkpointing: true
default_root_dir: null

# Single GPU specific
sync_batchnorm: false  # Not needed for single GPU

# Debugging
fast_dev_run: false
overfit_batches: 0
detect_anomaly: false

# Early stopping patience
patience: 10
